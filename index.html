<!DOCTYPE HTML>
<!--
	Read Only by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Zhenhan Huang's Personal Webpage</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
	</head>
	<body class="is-preload">

		<!-- Header -->
			<section id="header">
				<header>
					<span class="image avatar"><img src="images/portrait.jpg" alt="Zhenhan Huang" /></span>
					<h1 id="logo"><a href="#">Zhenhan Huang</a></h1>
					<!-- <p>After all, tomorrow is another day</p> -->
					<p>Without yesterday's nut holding its<br />
					ground, there is no today's mighty oak</p>
				</header>
				<nav id="nav">
					<ul>
						<li><a href="#one" class="active">About Me</a></li>
						<li><a href="#two">News</a></li>
						<li><a href="#three">Education</a></li>
						<li><a href="#four">Publication</a></li>
						<li><a href="#five">Research Directions</a></li>
					</ul>
				</nav>
				<footer>
					<ul class="icons">
						<li><a href="https://github.com/CNSaber" class="icon fa-github-square"><span class="label">Github</span></a></li>
						<li><a href="https://www.linkedin.com/in/zhenhan-huang-mlns" class="icon fa-linkedin-square"><span class="label">Linkedin</span></a></li>
						<li><a href="mailto:huangz12@rpi.edu" class="icon fa fa-envelope-square"><span class="label">Linkedin</span></a></li>
					</ul>
				</footer>
			</section>

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Main -->
					<div id="main">

						<!-- One -->
						<section id="one">
							<div class="image main" data-position="center">
								<img src="images/raphael_school_of_athens.jpg" style="width: 100%; object-fit: contain" alt="" />
							</div>
							<div class="container">
								<header class="major">
									<h2>Zhenhan Huang</h2>
									<h4 style="color:#666">I am a <span class="typing" style="font-weight: 300; color:#74A8E8"></span></h4>
								</header>
								<p>Hi there! My name is Zhenhan Huang (黄臻瀚). I am a third year graduate student in the department of computer science, Rensselaer Polytechnic Institute, Troy, New York, United States. I am fortunate enough to be advised by Prof. <a href="https://www.gaojianxi.com"><font color="#6F9FD8">Jianxi Gao</font></a>.</p>
								<p>My research interests align broadly with deep learning in computer vision and natural language processing. My current research focuses on meta learning and multimodal deep learning.</p>
							</div>
						</section>

						<!-- Two -->
                        <section id="two">
                            <div class="container">
                                <h3>News</h3>
                                <ul>
									<li>[2025.05] I did 2025 summer research intern at <a href="https://vectorinstitute.ai/"><font color="#6F9FD8">Vector Institute</font></a>. My research topic is multi-agent collaboration.</li>
									<li>[2025.04] Our work "Differentiable Prompt Learning for Vision Language Models" was accepted by <i>IJCAI 2025</i>.</li>
									<li>[2025.04] Our work "Language Models Are Good Tabular Learners" was accepted by <i>TMLR</i>.</li>
									<li>[2024.12] Our work "Modular Prompt Learning Improves Vision-Language Models" was accepted by <i>ICASSP 2025</i>.</li>
									<li>[2024.07] Our work "Graph is all you need? Lightweight Data-Agnostic Neural Architecture Search Without Training" was accepted by <i>AutoML 2024 workshop</i>.</li>
									<li>[2024.04] Our work "Network Properties Determine Neural Network Performance" was accepted by <i>Nature Communication</i>.</li>
									<li>[2023.10] I was fortunate to be supported by IBM-RPI Future of Computing Research Collaboration (FCRC) grant.</li>
									<li>[2023.05] I went to <a href="https://research.ibm.com/labs/watson/"><font color="#6F9FD8">IBM Thomas J. Watson Research Center</font></a> for 2023 summer intern. My research topic was to adapt large language models in the tabular data domain.</li>
									<li>[2022.08] I was enrolled in the Ph.D. program in computer science of Rensselaer Polytechnic Institute.</li>
                                </ul>
                            </div>
                        </section>

						<!-- Three -->
                        <section id="three">
                            <div class="container">
                                <h3>Education</h3>
                                <ul>
                                    <li><b>Ph.D.</b> in Computer Science, Rensselaer Polytechnic Institute<br>
                                    2022 - Present, GPA: 4.0/4.0
                                    </li>
                                    <li><b>M.S.</b> in Computer Science, Rensselaer Polytechnic Institute<br>
                                    2021 - 2022, GPA: 4.0/4.0</li>
                                    <li><b>Ph.D.</b> in Materials Engineering, Rensselaer Polytechnic Institute<br>
                                    2017 - 2022, GPA: 3.8/4.0</li>
                                    <li><b>M.S.</b> in Materials Engineering, Harbin Institute of Technology<br>
                                    2015 - 2017, GPA: 3.5/4.0</li>
                                    <li><b>B.S.</b> in Materials Engineering, Harbin Institute of Technology<br>
									2011 - 2015, GPA: 3.7/4.0</li>
                                </ul>
                            </div>
                        </section>

						<!-- Four -->
                        <section id="four">
                            <div class="container">
                                <h3>Publication</h3>
                                <ol>
									<li>
										Chunheng Jiang<sup>*</sup>, <b>Zhenhan Huang</b><sup>*</sup>, Tejaswini Pedapati, Pin-Yu Chen, Yizhou Sun and Jianxi Gao. Network Properties Determine Neural Network Performance. <i>Nature Communication</i>. (* Equal contribution). [<a href="https://www.nature.com/articles/s41467-024-48069-8"><font color="#6F9FD8">PDF</font></a>][<a href="https://codeocean.com/capsule/6480460/tree/v1"><font color=#6F9FD8>Code</font></a>]
									</li>
									<li>
										<b>Zhenhan Huang</b>, Tejaswini Pedapati, Pin-Yu Chen, Chunheng Jiang and Jianxi Gao. Graph is All You Need? Lightweight Data-Agnostic Neural Architecture Search Without Training. <i>AutoML 2024 Workshop</i>. [<a href="https://openreview.net/pdf?id=0DWTTOvx73"><font color="#6F9FD8">PDF</font></a>]&nbsp;[<a href="https://github.com/Zhenhan-Huang/NASGraph-Public"><font color=#6F9FD8>Code</font></a>]
									</li>
									<li>
										Aamod Khatiwada, Harsha Kokel, Ibrahim Abdelaziz, Subhajit Chaudhury, Julian Dolby, Oktie Hassanzadeh, <b>Zhenhan Huang</b>, Tejaswini Pedapati, Horst Samulowitz, Kavitha Srinivas. TabSketchFM: Sketch-based Tabular Representation
										Learning for Data Discovery over Data Lakes. <i>NeurIPS 2024 Workshop</i>. <i>ICDE 2025</i>. [<a href="https://arxiv.org/pdf/2407.01619"><font color="#6F9FD8">PDF</font></a>]
									</li>
									<li>
										<b>Zhenhan Huang</b>, Tejaswini Pedapati, Pin-Yu Chen and Jianxi Gao. Modular Prompt Learning Improves Vision-Language Models. <i>ICASSP 2025</i>. [<a href="https://arxiv.org/pdf/2502.14125"><font color="#6F9FD8">PDF</font></a>][<a href="https://github.com/Zhenhan-Huang/Modular-Prompt-Learning"><font color=#6F9FD8>Code</font></a>]
									</li>
									<li>
										<b>Zhenhan Huang</b>, Kavitha Srinivas, Horst Samulowitz, Niharika S. D'Souza, Charu C. Aggarwal, Pin-Yu Chen, Jianxi Gao. Language Models Are Good Tabular Learners. <i>TMLR</i>. [<a href="https://openreview.net/pdf?id=6o3vVBWYis"><font color="#6F9FD8">PDF</font></a>][<a href="https://github.com/Zhenhan-Huang/TDTransformer"><font color=#6F9FD8>Code</font></a>]
									</li>
									<li>
										<b>Zhenhan Huang</b>, Tejaswini Pedapati, Pin-Yu Chen and Jianxi Gao. Differentiable Prompt Learning for Vision Language Models. <i>IJCAI 2025</i>. [<a href="https://www.ijcai.org/proceedings/2025/0606.pdf"><font color="#6F9FD8">PDF</font></a>][<a href="https://github.com/Zhenhan-Huang/Differentiable-Prompt-Learn"><font color=#6F9FD8>Code</font></a>][<a href="https://zhenhan-huang.github.io/Differentiable-Prompt-Learn/"><font color=#6F9FD8>Project</font></a>]
									</li>
                                    <!-- <li>
                                    <b>Paper name</b><br>
                                    <b>Tom Josh</b>, Jerry Josh, Sam Josh<br>
                                    <i>Conference Name</i> (<b>Abbreviation</b>)<br>
                                    [<a href="weblink"><font color="#6F9FD8">PDF</font></a>]&nbsp;[<a href="weblink"><font color="#6F9FD8">Code</font></a>]
                                    </li> -->
                                </ol>
                                </div>
                            </div>
                        </section>

						<!-- Five -->
						<section id="five">
							<div class="container">
								<h3>Research Directions</h3>
								<!-- <p> Neural architecture search (NAS). </p> -->
								<div class="features">
									<article>
										<a href="#" class="image"><img src="images/neuralnetwork2graph.png" alt="" /></a>
										<div class="inner">
											<h4>Neural Architecture Search</h4>
											<p>We aimed to bridge neural architecture space to graph space. The connection was based on training dynamics or forward propagation. Neural architectures were evaluated through the lens of graphs. Related work:</p>
											<ul style="margin-top: -1em;">
												<li>Network Properties Determine Neural Network Performance</li>
												<li>Graph is All You Need? Lightweight Data-Agnostic Neural Architecture Search Without Training	</li>
											</ul>
										</div>
									</article>
									<!-- <article>
										<a href="#" class="image"><img src="images/pic02.jpg" alt="" /></a>
										<div class="inner">
											<h4>Large Language Model</h4>
											<p>Integer eu ante ornare amet commetus vestibulum blandit integer in curae ac faucibus integer adipiscing ornare amet.</p>
										</div>
									</article> -->
								</div>
								<!-- <p> Large Language Model. </p> -->
								<div class="features">
									<article>
										<a href="#" class="image"><img src="images/pos_embed.png" alt="" /></a>
										<div class="inner">
										<h4>Natural Language Processing</h4>
										<p>We aimed to adapt transformer-based language model to tabular data domain. Embedding approaches were proposed to help language model to understand structured data. Unsupervised pretraining and supervised fine-tuning were applied in the training scheme. Related work:</p>
										<ul style="margin-top: -1em;">
											<li>TabSketchFM: Sketch-based Tabular Representation Learning for Data Discovery over Data Lakes.</li>
											<li>Language Models Are Good Tabular Learners.</li>
										</ul>
									</article>
								</div>
								<!-- <p> Parameter Efficient Fine-Tuning (PEFT). </p> -->
								<div class="features">
									<article>
										<a href="#" class="image"><img src="images/dpl_peft.png" alt="" /></a>
										<div class="inner">
										<h4>Parameter-Efficient Fine-Tuning</h4>
										<p>We aimed to introduce heterogeneous design in the prompting methods for vision-language models. Through prompting, pretrained foundational vision-language models were adapted to downstream tasks. Related work:</p>
										<ul style="margin-top: -1em;">
											<li>Modular Prompt Learning Improves Vision-Language Models</li>
											<li>Differentiable Prompt Learning for Vision Language Models</li>
										</ul>
									</article>
								</div>
							</div>
						</section>

						<!-- Six -->
						<section id="six">
							<div class="container">
								<h3>Contact Info</h3>
								<p>Feel free to reach out with any questions or potential collaborations:</p>
								<ul class="feature-icons">
									<li class="ico solid fa-github"><a href="https://github.com/Zhenhan-Huang">Github</a></li>
									<li class="ico solid fa-linkedin"><a href="https://www.linkedin.com/in/zhenhan-huang-mlns">Linkedin</a></li>
									<li class="icon solid fa-envelope"><a href="mailto:huangz12@rpi.edu">Email</a></li>
								</ul>
							</div>
						</section>

						<!-- Three -->
                        <!-- <section id="three">
                            <div class="container">
                                <h3>Things I Can Do</h3>
                                <p>Integer eu ante ornare amet commetus vestibulum blandit integer in curae ac faucibus integer non. Adipiscing cubilia elementum integer lorem ipsum dolor sit amet.</p>
                                <ul class="feature-icons">
                                    <li class="icon solid fa-code">Write all the code</li>
                                    <li class="icon solid fa-cubes">Stack small boxes</li>
                                    <li class="icon solid fa-book">Read books and stuff</li>
                                    <li class="icon solid fa-coffee">Drink much coffee</li>
                                    <li class="icon solid fa-bolt">Lightning bolt</li>
                                    <li class="icon solid fa-users">Shadow clone technique</li>
                                </ul>
                            </div>
                        </section> -->

					</div>

				<!-- Footer -->
					<section id="footer">
						<div class="container">
							<ul class="copyright">
								<li>&copy; Zhenhan Huang. All rights reserved.</li><li>Design: HTML5 UP</li>
							</ul>
						</div>
					</section>

			</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.scrollex.min.js"></script>
			<script src="assets/js/jquery.scrolly.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

		<!-- typed.js -->
		<script src="assets/js/typed.min.js"></script>
		<script type="text/javascript">
			var typed = new Typed('.typing',{
			strings: ["Deep Learning Researcher", "Self-Motivated Coder", "Sports Enthusiast", "Probabilistic Believer"],
			loop: true,
			typeSpeed: 80,
			backSpeed: 40
			});
		</script>

	</body>
</html>